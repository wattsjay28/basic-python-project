{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de44a7d2",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\"> <h1 style=\"color:green; margin-bottom:20px\">Reviewer's comment v1</h1>\n",
    "\n",
    "Hello Justin, my name is Dmitrii. I'm going to review your project! Nice to meet you! üôå\n",
    "\n",
    "You can find my comments under the heading **¬´Review¬ª**. I will categorize my comments in green, blue or red boxes like this:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Success:</b> if everything is done successfully\n",
    "</div>\n",
    "<div class=\"alert alert-warning\">\n",
    "    <b>Remarks:</b> if I can give some recommendations or ways to improve the project\n",
    "   \n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    "    <b>Needs fixing:</b> if the block requires some corrections. Work can't be accepted with the red comments\n",
    "</div>\n",
    "\n",
    "Please don't remove my comments :) If you have any questions don't hesitate to respond to my comments in a different section. \n",
    "<div class=\"alert alert-info\"> <b>Student comments:</b> For example like this</div>   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f8f4f",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "<b>Overall Feedback</b> \n",
    "    \n",
    "- Overall well done! I can see that a lot of effort has been made! Your project looks very good and you accomplished impressive results.\n",
    "- However, there are some comments/areas left to fix (in red boxes with the title - Reviewer's comment v1:). \n",
    "    \n",
    "And of course, if you have any questions along the way, remember that you can always reach out to your tutor for any clarification.\n",
    "    \n",
    "I will wait for you to send me a new version of the project :)\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b397a8f",
   "metadata": {},
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\">\n",
    "<b>Reviewer's comment v2:</b>\n",
    "    \n",
    "<b>Overall Feedback</b> \n",
    "\n",
    "Thank you for making all improvements in your project! It looks perfect now and there are no critical issues. \n",
    "    \n",
    "Please keep up great work and don't hesitate to use this project as a reference in your future sprints. \n",
    "   \n",
    "Good luck on the next project üçÄ \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85a80d2",
   "metadata": {},
   "source": [
    "## Basic Python - Project <a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1262df4",
   "metadata": {},
   "source": [
    "## Introduction <a id='intro'></a>\n",
    "In this project, you will work with data from the entertainment industry. You will study a dataset with records on movies and shows. The research will focus on the \"Golden Age\" of television, which began in 1999 with the release of *The Sopranos* and is still ongoing.\n",
    "\n",
    "The aim of this project is to investigate how the number of votes a title receives impacts its ratings. The assumption is that highly-rated shows (we will focus on TV shows, ignoring movies) released during the \"Golden Age\" of television also have the most votes.\n",
    "\n",
    "### Stages \n",
    "Data on movies and shows is stored in the `/datasets/movies_and_shows.csv` file. There is no information about the quality of the data, so you will need to explore it before doing the analysis.\n",
    "\n",
    "First, you'll evaluate the quality of the data and see whether its issues are significant. Then, during data preprocessing, you will try to account for the most critical problems.\n",
    " \n",
    "Your project will consist of three stages:\n",
    " 1. Data overview\n",
    " 2. Data preprocessing\n",
    " 3. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfc79be",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "It is always helpful for the reader to have additional information about project tasks. It gives an overview of what you are going to achieve in this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0593ac",
   "metadata": {},
   "source": [
    "## Stage 1. Data overview <a id='data_review'></a>\n",
    "\n",
    "Open and explore the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ed00e",
   "metadata": {},
   "source": [
    "You'll need `pandas`, so import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1727d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5ba85",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "Well done! Required library has been imported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821beeb",
   "metadata": {},
   "source": [
    "Read the `movies_and_shows.csv` file from the `datasets` folder and save it in the `df` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83350546",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/datasets/movies_and_shows.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a926a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Reviewer's comment v1</b>\n",
    " \n",
    "Everything is correct here; however it's a good practice to use `try/except blocks` when performing file operations or other tasks that might fail due to external reasons, such as the file not being present, issues with file permissions, or incorrect file formats. This way, you can handle errors gracefully and provide a more user-friendly error message, rather than having the program crash unexpectedly.\n",
    "\n",
    "Here's how you can implement it:\n",
    "\n",
    "```\n",
    "try:\n",
    "    orders = pd.read_csv(local_path['orders'], sep=';')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    orders = pd.read_csv(server_path['orders'], sep=';')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd0a96d",
   "metadata": {},
   "source": [
    "Print the first 10 table rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd92001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name                      Character   r0le        TITLE   Type  \\\n",
      "0   Robert De Niro                  Travis Bickle  ACTOR  Taxi Driver  MOVIE   \n",
      "1     Jodie Foster                  Iris Steensma  ACTOR  Taxi Driver  MOVIE   \n",
      "2    Albert Brooks                            Tom  ACTOR  Taxi Driver  MOVIE   \n",
      "3    Harvey Keitel        Matthew 'Sport' Higgins  ACTOR  Taxi Driver  MOVIE   \n",
      "4  Cybill Shepherd                          Betsy  ACTOR  Taxi Driver  MOVIE   \n",
      "5      Peter Boyle                         Wizard  ACTOR  Taxi Driver  MOVIE   \n",
      "6   Leonard Harris      Senator Charles Palantine  ACTOR  Taxi Driver  MOVIE   \n",
      "7   Diahnne Abbott                Concession Girl  ACTOR  Taxi Driver  MOVIE   \n",
      "8      Gino Ardito             Policeman at Rally  ACTOR  Taxi Driver  MOVIE   \n",
      "9  Martin Scorsese  Passenger Watching Silhouette  ACTOR  Taxi Driver  MOVIE   \n",
      "\n",
      "   release Year              genres  imdb sc0re  imdb v0tes  \n",
      "0          1976  ['drama', 'crime']         8.2    808582.0  \n",
      "1          1976  ['drama', 'crime']         8.2    808582.0  \n",
      "2          1976  ['drama', 'crime']         8.2    808582.0  \n",
      "3          1976  ['drama', 'crime']         8.2    808582.0  \n",
      "4          1976  ['drama', 'crime']         8.2    808582.0  \n",
      "5          1976  ['drama', 'crime']         8.2    808582.0  \n",
      "6          1976  ['drama', 'crime']         8.2    808582.0  \n",
      "7          1976  ['drama', 'crime']         8.2    808582.0  \n",
      "8          1976  ['drama', 'crime']         8.2    808582.0  \n",
      "9          1976  ['drama', 'crime']         8.2    808582.0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e579aa91",
   "metadata": {},
   "source": [
    "Obtain the general information about the table with one command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf66d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85579 entries, 0 to 85578\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0      name       85579 non-null  object \n",
      " 1   Character     85579 non-null  object \n",
      " 2   r0le          85579 non-null  object \n",
      " 3   TITLE         85578 non-null  object \n",
      " 4     Type        85579 non-null  object \n",
      " 5   release Year  85579 non-null  int64  \n",
      " 6   genres        85579 non-null  object \n",
      " 7   imdb sc0re    80970 non-null  float64\n",
      " 8   imdb v0tes    80853 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 5.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f62a7",
   "metadata": {},
   "source": [
    "The table contains nine columns. The majority store the same data type: object. The only exceptions are `'release Year'` (int64 type), `'imdb sc0re'` (float64 type) and `'imdb v0tes'` (float64 type). Scores and votes will be used in our analysis, so it's important to verify that they are present in the dataframe in the appropriate numeric format. Three columns (`'TITLE'`, `'imdb sc0re'` and `'imdb v0tes'`) have missing values.\n",
    "\n",
    "According to the documentation:\n",
    "- `'name'` ‚Äî actor/director's name and last name\n",
    "- `'Character'` ‚Äî character played (for actors)\n",
    "- `'r0le '` ‚Äî the person's contribution to the title (it can be in the capacity of either actor or director)\n",
    "- `'TITLE '` ‚Äî title of the movie (show)\n",
    "- `'  Type'` ‚Äî show or movie\n",
    "- `'release Year'` ‚Äî year when movie (show) was released\n",
    "- `'genres'` ‚Äî list of genres under which the movie (show) falls\n",
    "- `'imdb sc0re'` ‚Äî score on IMDb\n",
    "- `'imdb v0tes'` ‚Äî votes on IMDb\n",
    "\n",
    "We can see three issues with the column names:\n",
    "1. Some names are uppercase, while others are lowercase.\n",
    "2. There are names containing whitespace.\n",
    "3. A few column names have digit '0' instead of letter 'o'. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4355de7b",
   "metadata": {},
   "source": [
    "### Conclusions <a id='data_review_conclusions'></a> \n",
    "\n",
    "Each row in the table stores data about a movie or show. The columns can be divided into two categories: the first is about the roles held by different people who worked on the movie or show (role, name of the actor or director, and character if the row is about an actor); the second category is information about the movie or show itself (title, release year, genre, imdb figures).\n",
    "\n",
    "It's clear that there is sufficient data to do the analysis and evaluate our assumption. However, to move forward, we need to preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a92bd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "Great data overview and correct conclusions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc9111",
   "metadata": {},
   "source": [
    "## Stage 2. Data preprocessing <a id='data_preprocessing'></a>\n",
    "Correct the formatting in the column headers and deal with the missing values. Then, check whether there are duplicates in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c850d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are duplicates in the data.\n",
      "                      name                  character      r0le  \\\n",
      "7561         Philip Greene  Baseball Fan (uncredited)     ACTOR   \n",
      "14512             Dan Levy                   Reporter     ACTOR   \n",
      "18952     Nicolas Le Nev??                    unknown  DIRECTOR   \n",
      "22456    John Iii Franklin                    Himself     ACTOR   \n",
      "29557         Claudio Roca                   Nicol?¬≠s     ACTOR   \n",
      "...                    ...                        ...       ...   \n",
      "85569       Jessica Cediel            Liliana Navarro     ACTOR   \n",
      "85570  Javier Gardeaz?¬≠bal   Agust??n \"Peluca\" Ort??z     ACTOR   \n",
      "85571        Carla Giraldo             Valery Reinoso     ACTOR   \n",
      "85572  Ana Mar??a S?¬≠nchez                    Lourdes     ACTOR   \n",
      "85577         Isabel Gaona                     Cacica     ACTOR   \n",
      "\n",
      "                                 title   type  release_year  \\\n",
      "7561                   How Do You Know  MOVIE          2010   \n",
      "14512  A Very Harold & Kumar Christmas  MOVIE          2011   \n",
      "18952                       Sammy & Co   SHOW          2014   \n",
      "22456                    Last Chance U   SHOW          2016   \n",
      "29557                   Narcos: Mexico   SHOW          2018   \n",
      "...                                ...    ...           ...   \n",
      "85569                          Lokillo  MOVIE          2021   \n",
      "85570                          Lokillo  MOVIE          2021   \n",
      "85571                          Lokillo  MOVIE          2021   \n",
      "85572                          Lokillo  MOVIE          2021   \n",
      "85577                          Lokillo  MOVIE          2021   \n",
      "\n",
      "                                 genres  imdb_sc0re  imdb_v0tes  \n",
      "7561     ['comedy', 'drama', 'romance']         5.4     50383.0  \n",
      "14512  ['comedy', 'fantasy', 'romance']         6.2     69562.0  \n",
      "18952         ['animation', 'european']         5.7        31.0  \n",
      "22456        ['documentation', 'sport']         8.4      6897.0  \n",
      "29557                ['drama', 'crime']         8.4     82042.0  \n",
      "...                                 ...         ...         ...  \n",
      "85569                        ['comedy']         3.8        68.0  \n",
      "85570                        ['comedy']         3.8        68.0  \n",
      "85571                        ['comedy']         3.8        68.0  \n",
      "85572                        ['comedy']         3.8        68.0  \n",
      "85577                        ['comedy']         3.8        68.0  \n",
      "\n",
      "[6994 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# the list of column names in the df table\n",
    "# Correct formatting in column headers\n",
    "df.rename(columns=lambda x: x.strip().replace(' ', '_').lower(), inplace=True)\n",
    "\n",
    "# Deal with missing values\n",
    "df.dropna(inplace=True)  # Drop rows with any missing values\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated()\n",
    "num_duplicates = duplicates.sum()\n",
    "\n",
    "if num_duplicates > 0:\n",
    "    print(\"There are duplicates in the data.\")\n",
    "    print(df[duplicates])  # Display duplicate rows\n",
    "else:\n",
    "    print(\"There are no duplicates in the data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f966df9",
   "metadata": {},
   "source": [
    "Change the column names according to the rules of good style:\n",
    "* If the name has several words, use snake_case\n",
    "* All characters must be lowercase\n",
    "* Remove whitespace\n",
    "* Replace zero with letter 'o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a1dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to convert column names to snake_case and replace '0' with 'o'\n",
    "def convert_to_snake_case(column_name):\n",
    "    return column_name.strip().replace(' ', '_').replace('0', 'o').lower()\n",
    "\n",
    "# Rename columns using the defined function\n",
    "df.rename(columns=convert_to_snake_case, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fbd04",
   "metadata": {},
   "source": [
    "Check the result. Print the names of the columns once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb6527f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'character', 'role', 'title', 'type', 'release_year', 'genres',\n",
      "       'imdb_score', 'imdb_votes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# checking result: the list of column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e686f93",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "It is great that you correctly applied `replace` function. As a second approach a `rename` function could be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d9c319",
   "metadata": {},
   "source": [
    "### Missing values <a id='missing_values'></a>\n",
    "First, find the number of missing values in the table. To do so, combine two `pandas` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c427f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8272df3",
   "metadata": {},
   "source": [
    "Not all missing values affect the research: the single missing value in `'title'` is not critical. The missing values in columns `'imdb_score'` and `'imdb_votes'` represent around 6% of all records (4,609 and 4,726, respectively, of the total 85,579). This could potentially affect our research. To avoid this issue, we will drop rows with missing values in the `'imdb_score'` and `'imdb_votes'` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "599d5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['imdb_score', 'imdb_votes'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f379f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values after dropping rows: name            0\n",
      "character       0\n",
      "role            0\n",
      "title           0\n",
      "type            0\n",
      "release_year    0\n",
      "genres          0\n",
      "imdb_score      0\n",
      "imdb_votes      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_after_drop = df.isna().sum()\n",
    "print(\"Number of missing values after dropping rows:\", missing_values_after_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b179d7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1</b>\n",
    "    \n",
    "Great that you selected `isna()` method to find missing values! \n",
    "\n",
    "It is also sometimes helpful to check not only the total amount of missing values in each column but also look at the percentage of missing values. It helps to understand the overall impact. You can check percentage using, for example, this code:\n",
    "\n",
    "`df.isnull().sum()/len(df)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55c0b0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing values in the DataFrame after dropping rows.\n"
     ]
    }
   ],
   "source": [
    "missing_values_per_column = df.isnull().sum()\n",
    "\n",
    "# Check if there are any missing values left in the DataFrame\n",
    "total_missing_values = missing_values_per_column.sum()\n",
    "# Check if there are any missing values left in the DataFrame\n",
    "if total_missing_values == 0:\n",
    "    print(\"There are no missing values in the DataFrame after dropping rows.\")\n",
    "else:\n",
    "    print(\"There are still missing values in the DataFrame after dropping rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff00a0a4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    "    \n",
    "Everything is correct here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc7aa0",
   "metadata": {},
   "source": [
    "### Duplicates <a id='duplicates'></a>\n",
    "Find the number of duplicate rows in the table using one command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9227df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicate_rows = df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6eb0fc",
   "metadata": {},
   "source": [
    "Review the duplicate rows to determine if removing them would distort our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf32fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "                      name                  character      role  \\\n",
      "7561         Philip Greene  Baseball Fan (uncredited)     ACTOR   \n",
      "14512             Dan Levy                   Reporter     ACTOR   \n",
      "18952     Nicolas Le Nev??                    unknown  DIRECTOR   \n",
      "22456    John Iii Franklin                    Himself     ACTOR   \n",
      "29557         Claudio Roca                   Nicol?¬≠s     ACTOR   \n",
      "...                    ...                        ...       ...   \n",
      "85569       Jessica Cediel            Liliana Navarro     ACTOR   \n",
      "85570  Javier Gardeaz?¬≠bal   Agust??n \"Peluca\" Ort??z     ACTOR   \n",
      "85571        Carla Giraldo             Valery Reinoso     ACTOR   \n",
      "85572  Ana Mar??a S?¬≠nchez                    Lourdes     ACTOR   \n",
      "85577         Isabel Gaona                     Cacica     ACTOR   \n",
      "\n",
      "                                 title   type  release_year  \\\n",
      "7561                   How Do You Know  MOVIE          2010   \n",
      "14512  A Very Harold & Kumar Christmas  MOVIE          2011   \n",
      "18952                       Sammy & Co   SHOW          2014   \n",
      "22456                    Last Chance U   SHOW          2016   \n",
      "29557                   Narcos: Mexico   SHOW          2018   \n",
      "...                                ...    ...           ...   \n",
      "85569                          Lokillo  MOVIE          2021   \n",
      "85570                          Lokillo  MOVIE          2021   \n",
      "85571                          Lokillo  MOVIE          2021   \n",
      "85572                          Lokillo  MOVIE          2021   \n",
      "85577                          Lokillo  MOVIE          2021   \n",
      "\n",
      "                                 genres  imdb_score  imdb_votes  \n",
      "7561     ['comedy', 'drama', 'romance']         5.4     50383.0  \n",
      "14512  ['comedy', 'fantasy', 'romance']         6.2     69562.0  \n",
      "18952         ['animation', 'european']         5.7        31.0  \n",
      "22456        ['documentation', 'sport']         8.4      6897.0  \n",
      "29557                ['drama', 'crime']         8.4     82042.0  \n",
      "...                                 ...         ...         ...  \n",
      "85569                        ['comedy']         3.8        68.0  \n",
      "85570                        ['comedy']         3.8        68.0  \n",
      "85571                        ['comedy']         3.8        68.0  \n",
      "85572                        ['comedy']         3.8        68.0  \n",
      "85577                        ['comedy']         3.8        68.0  \n",
      "\n",
      "[6994 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "\n",
    "# Print duplicate rows\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a67a18",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment v1</b>\n",
    "\n",
    "I noticed you've been using the `print` function to view dataframes. While `print` does the job of showing the results, Jupyter Notebooks offer a more powerful and visually appealing option through the `display` function.\n",
    "\n",
    "Using display instead of print has several benefits, especially for displaying pandas DataFrames:\n",
    "\n",
    "- Improved Readability: display renders DataFrame in a nicely formatted HTML table that is easier to read and interpret compared to the plain text output of print.\n",
    "- Better Formatting: With display, the output takes advantage of HTML styling, which means your data can be presented with better spacing, alignment, and even coloring for different data types.\n",
    "- Interactivity: Jupyter Notebooks can integrate with tools like IPython.display to provide interactive features in displaying complex objects, images, and even interactive widgets alongside DataFrames.\n",
    "    \n",
    "For example, instead of using `print(last5dupe)`, you can simply call `display(last5dupe)` to see a more readable and visually appealing table of your sorted data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed6640",
   "metadata": {},
   "source": [
    "There are two clear duplicates in the printed rows. We can safely remove them.\n",
    "Call the `pandas` method for getting rid of duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "724d5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56789937",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment v1</b>\n",
    "    \n",
    "Note that it is also required additionally to re-create the indexes in your dataframe. To achieve that, you can use `reset_index()`.\n",
    "    \n",
    "Without that, the index column will not be ordinal anymore, as `drop_duplicates()` deleted some lines, hence the dataframe becomes less informative.\n",
    "    \n",
    "    \n",
    "You can read about it here: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html\n",
    "    \n",
    "And parameter `drop=True` could be helpful to rewrite existent index instead of creating a second ordinal column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c77ba",
   "metadata": {},
   "source": [
    "Check for duplicate rows once more to make sure you have removed all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8091a9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows found after removal.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows after removal\n",
    "duplicate_rows_after_removal = df[df.duplicated()]\n",
    "\n",
    "# Print duplicate rows (if any)\n",
    "if duplicate_rows_after_removal.empty:\n",
    "    print(\"No duplicate rows found after removal.\")\n",
    "else:\n",
    "    print(\"Duplicate Rows After Removal:\")\n",
    "    print(duplicate_rows_after_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d802b07",
   "metadata": {},
   "source": [
    "Now get rid of implicit duplicates in the `'type'` column. For example, the string `'SHOW'` can be written in different ways. These kinds of errors will also affect the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f987ed",
   "metadata": {},
   "source": [
    "Print a list of unique `'type'` names, sorted in alphabetical order. To do so:\n",
    "* Retrieve the intended dataframe column \n",
    "* Apply a sorting method to it\n",
    "* For the sorted column, call the method that will return all unique column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d7b0ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVIE\n",
      "SHOW\n",
      "movies\n",
      "shows\n",
      "the movie\n",
      "tv\n",
      "tv series\n",
      "tv show\n",
      "tv shows\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the 'type' column\n",
    "type_column = df['type']\n",
    "\n",
    "# Sort the 'type' column alphabetically\n",
    "sorted_types = type_column.sort_values()\n",
    "\n",
    "# Get the unique values\n",
    "unique_types = sorted_types.unique()\n",
    "\n",
    "# Print the unique 'type' names\n",
    "for t in unique_types:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e8b18",
   "metadata": {},
   "source": [
    "Look through the list to find implicit duplicates of `'show'` (`'movie'` duplicates will be ignored since the assumption is about shows). These could be names written incorrectly or alternative names of the same genre.\n",
    "\n",
    "You will see the following implicit duplicates:\n",
    "* `'shows'`\n",
    "* `'SHOW'`\n",
    "* `'tv show'`\n",
    "* `'tv shows'`\n",
    "* `'tv series'`\n",
    "* `'tv'`\n",
    "\n",
    "To get rid of them, declare the function `replace_wrong_show()` with two parameters: \n",
    "* `wrong_shows_list=` ‚Äî the list of duplicates\n",
    "* `correct_show=` ‚Äî the string with the correct value\n",
    "\n",
    "The function should correct the names in the `'type'` column from the `df` table (i.e., replace each value from the `wrong_shows_list` list with the value in `correct_show`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bff944f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_wrong_show(wrong_shows_list, correct_show):\n",
    "    for show in wrong_shows_list:\n",
    "        df['type'].replace(show, correct_show, inplace=True)\n",
    "# REMOVED 'MOVIE' FROM SHOW NAMES        \n",
    "# Given list of incorrect 'show' names\n",
    "wrong_shows_list = ['SHOW', 'shows', 'tv', 'tv series', 'tv show', 'tv shows']\n",
    "# Correct name for the shows\n",
    "correct_show = 'SHOW'\n",
    "# Call the function with the lists defined above\n",
    "replace_wrong_show(wrong_shows_list, correct_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d13a6",
   "metadata": {},
   "source": [
    "Call `replace_wrong_show()` and pass it arguments so that it clears implicit duplicates and replaces them with `SHOW`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2217e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_wrong_show(['shows', 'SHOW', 'tv show', 'tv shows', 'tv series', 'tv'], 'SHOW')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b09f7",
   "metadata": {},
   "source": [
    "Make sure the duplicate names are removed. Print the list of unique values from the `'type'` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25d49d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MOVIE', 'the movie', 'SHOW', 'movies']\n"
     ]
    }
   ],
   "source": [
    "unique_types = df['type'].drop_duplicates().tolist()\n",
    "print(unique_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378d89b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Reviewer's comment v1</b>\n",
    "    \n",
    "`movie` duplicates should be ignored since the assumption is about shows. \n",
    "    \n",
    "Could you please update that? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10618f03",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v2</b>\n",
    "    \n",
    "Well done! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2049e",
   "metadata": {},
   "source": [
    "### Conclusions <a id='data_preprocessing_conclusions'></a>\n",
    "We detected three issues with the data:\n",
    "\n",
    "- Incorrect header styles\n",
    "- Missing values\n",
    "- Duplicate rows and implicit duplicates\n",
    "\n",
    "The headers have been cleaned up to make processing the table simpler.\n",
    "\n",
    "All rows with missing values have been removed. \n",
    "\n",
    "The absence of duplicates will make the results more precise and easier to understand.\n",
    "\n",
    "Now we can move on to our analysis of the prepared data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa0f1b1",
   "metadata": {},
   "source": [
    "## Stage 3. Data analysis <a id='hypotheses'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb6a0e",
   "metadata": {},
   "source": [
    "Based on the previous project stages, you can now define how the assumption will be checked. Calculate the average amount of votes for each score (this data is available in the `imdb_score` and `imdb_votes` columns), and then check how these averages relate to each other. If the averages for shows with the highest scores are bigger than those for shows with lower scores, the assumption appears to be true.\n",
    "\n",
    "Based on this, complete the following steps:\n",
    "\n",
    "- Filter the dataframe to only include shows released in 1999 or later.\n",
    "- Group scores into buckets by rounding the values of the appropriate column (a set of 1-10 integers will help us make the outcome of our calculations more evident without damaging the quality of our research).\n",
    "- Identify outliers among scores based on their number of votes, and exclude scores with few votes.\n",
    "- Calculate the average votes for each score and check whether the assumption matches the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2cb51",
   "metadata": {},
   "source": [
    "To filter the dataframe and only include shows released in 1999 or later, you will take two steps. First, keep only titles published in 1999 or later in our dataframe. Then, filter the table to only contain shows (movies will be removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a704aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name                character   role      title  type  \\\n",
      "1664       Jeff Probst           Himself - Host  ACTOR   Survivor  SHOW   \n",
      "2076     Mayumi Tanaka  Monkey D. Luffy (voice)  ACTOR  One Piece  SHOW   \n",
      "2077      Kazuya Nakai     Roronoa Zoro (voice)  ACTOR  One Piece  SHOW   \n",
      "2078     Akemi Okamura             Nami (voice)  ACTOR  One Piece  SHOW   \n",
      "2079  Kappei Yamaguchi            Usopp (voice)  ACTOR  One Piece  SHOW   \n",
      "\n",
      "      release_year                                             genres  \\\n",
      "1664          2000                                        ['reality']   \n",
      "2076          1999  ['animation', 'action', 'comedy', 'drama', 'fa...   \n",
      "2077          1999  ['animation', 'action', 'comedy', 'drama', 'fa...   \n",
      "2078          1999  ['animation', 'action', 'comedy', 'drama', 'fa...   \n",
      "2079          1999  ['animation', 'action', 'comedy', 'drama', 'fa...   \n",
      "\n",
      "      imdb_score  imdb_votes  \n",
      "1664         7.4     24687.0  \n",
      "2076         8.8    117129.0  \n",
      "2077         8.8    117129.0  \n",
      "2078         8.8    117129.0  \n",
      "2079         8.8    117129.0  \n"
     ]
    }
   ],
   "source": [
    "# Filter the dataframe to only include shows released in 1999 or later\n",
    "shows_1999_or_later = df[(df['release_year'] >= 1999) & (df['type'] == 'SHOW')]\n",
    "\n",
    "# Check the first few rows to verify the filtering\n",
    "print(shows_1999_or_later.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e1b91",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1</b>\n",
    "\n",
    "You've filterd the data required data correctly. \n",
    "    \n",
    "    \n",
    "Additionally there are other methods that could be helpful to filter your data, for example:`query()`.\n",
    "\n",
    "`df_filtered = df.query('type == \"show\"')`\n",
    "    \n",
    "You can read about them additionally here: \n",
    "https://towardsdatascience.com/10-examples-that-will-make-you-use-pandas-query-function-more-often-a8fb3e9361cb\n",
    "https://towardsdatascience.com/how-to-use-loc-and-iloc-for-selecting-data-in-pandas-bd09cb4c3d79    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "128dc6a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name             character   role  \\\n",
      "163  Graham Chapman               Various  ACTOR   \n",
      "164   Michael Palin  Various / \"It's\" man  ACTOR   \n",
      "165     Terry Jones               Various  ACTOR   \n",
      "166       Eric Idle               Various  ACTOR   \n",
      "167   Terry Gilliam               Various  ACTOR   \n",
      "\n",
      "                            title  type  release_year                  genres  \\\n",
      "163  Monty Python's Flying Circus  SHOW          1969  ['comedy', 'european']   \n",
      "164  Monty Python's Flying Circus  SHOW          1969  ['comedy', 'european']   \n",
      "165  Monty Python's Flying Circus  SHOW          1969  ['comedy', 'european']   \n",
      "166  Monty Python's Flying Circus  SHOW          1969  ['comedy', 'european']   \n",
      "167  Monty Python's Flying Circus  SHOW          1969  ['comedy', 'european']   \n",
      "\n",
      "     imdb_score  imdb_votes  \n",
      "163         8.8     73424.0  \n",
      "164         8.8     73424.0  \n",
      "165         8.8     73424.0  \n",
      "166         8.8     73424.0  \n",
      "167         8.8     73424.0  \n"
     ]
    }
   ],
   "source": [
    "# Filter the dataframe to only include shows (movies are removed)\n",
    "shows_only = df[df['type'] == 'SHOW']\n",
    "\n",
    "# Check the first few rows to verify the filtering\n",
    "print(shows_only.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9648040c",
   "metadata": {},
   "source": [
    "The scores that are to be grouped should be rounded. For instance, titles with scores like 7.8, 8.1, and 8.3 will all be placed in the same bucket with a score of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54bbd5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       imdb_score  rounded_score\n",
      "85573         3.8            4.0\n",
      "85574         3.8            4.0\n",
      "85575         3.8            4.0\n",
      "85576         3.8            4.0\n",
      "85578         3.8            4.0\n"
     ]
    }
   ],
   "source": [
    "# Round the 'imdb_score' column\n",
    "df['rounded_score'] = df['imdb_score'].round()\n",
    "\n",
    "# Check the outcome with tail()\n",
    "print(df[['imdb_score', 'rounded_score']].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dbd00a",
   "metadata": {},
   "source": [
    "It is now time to identify outliers based on the number of votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8b55e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounded_score\n",
      "2.0       21\n",
      "3.0       51\n",
      "4.0      215\n",
      "5.0      539\n",
      "6.0     1366\n",
      "7.0     1435\n",
      "8.0      920\n",
      "9.0       85\n",
      "10.0       1\n",
      "Name: imdb_votes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group the data by rounded scores and count unique values of imdb_votes in each group\n",
    "outliers = df.groupby('rounded_score')['imdb_votes'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba6daae",
   "metadata": {},
   "source": [
    "Based on the aggregation performed, it is evident that scores 2 (24 voted shows), 3 (27 voted shows), and 10 (only 8 voted shows) are outliers. There isn't enough data for these scores for the average number of votes to be meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd468c46",
   "metadata": {},
   "source": [
    "To obtain the mean numbers of votes for the selected scores (we identified a range of 4-9 as acceptable), use conditional filtering and grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1867e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rounded_score     imdb_votes\n",
      "0            4.0    8943.007876\n",
      "1            5.0   14421.066403\n",
      "2            6.0   29552.217666\n",
      "3            7.0   54061.490793\n",
      "4            8.0  162813.093748\n",
      "5            9.0  577107.221778\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to include scores in the range 4-9\n",
    "filtered_df = df[(df['rounded_score'] >= 4) & (df['rounded_score'] <= 9)]\n",
    "# Used rounded_score column\n",
    "# Group the filtered DataFrame by 'rounded_score' and calculate the mean number of votes\n",
    "average_votes_per_score = filtered_df.groupby('rounded_score')['imdb_votes'].mean().reset_index()\n",
    "\n",
    "# Print the result\n",
    "print(average_votes_per_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc829412",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Reviewer's comment v1</b>\n",
    "    \n",
    "Here and below `rounded_score` column should be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57628f80",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v2</b>\n",
    "    \n",
    "Thank you for updating that. Everything is correct now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a66d14",
   "metadata": {},
   "source": [
    "Now for the final step! Round the column with the averages, rename both columns, and print the dataframe in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5999051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rounded_score  average_votes\n",
      "5            9.0       577107.0\n",
      "4            8.0       162813.0\n",
      "3            7.0        54061.0\n",
      "2            6.0        29552.0\n",
      "1            5.0        14421.0\n",
      "0            4.0         8943.0\n"
     ]
    }
   ],
   "source": [
    "# Round the column with averages\n",
    "average_votes_per_score['imdb_votes'] = average_votes_per_score['imdb_votes'].round()\n",
    "# Used rounded_score column\n",
    "# Rename columns\n",
    "average_votes_per_score.columns = ['rounded_score', 'average_votes']\n",
    "\n",
    "# Print the DataFrame in descending order\n",
    "print(average_votes_per_score.sort_values(by='average_votes', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07386d",
   "metadata": {},
   "source": [
    "The assumption macthes the analysis: the shows with the top 3 scores have the most amounts of votes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e29a37",
   "metadata": {},
   "source": [
    "## Conclusion <a id='hypotheses'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984766a3",
   "metadata": {},
   "source": [
    "The research done confirms that highly-rated shows released during the \"Golden Age\" of television also have the most votes. While shows with score 4 have more votes than ones with scores 5 and 6, the top three (scores 7-9) have the largest number. The data studied represents around 94% of the original set, so we can be confident in our findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78caa4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment v1:</b>\n",
    " \n",
    "Overall you did a great research. I only left some feedback in the notebook.\n",
    "    \n",
    "A small tip regarding overall conclusion in the project: \n",
    "    It represents the overall work progress that you achieved. On a real project, this is probably the only thing the business will read. Therefore, it is crucial to indicate in a structured way all conclusions that you made on each step in the project.\n",
    "\n",
    "For example:\n",
    "\n",
    "- Replaced missing values in the following data with the following method.\n",
    "- Replaced data types in the following columns.\n",
    "- etc.\n",
    "- We observe that ... factors impact ... \n",
    "- My analysis show ...\n",
    "- I can recommend the following next steps / activities ...\n",
    "\n",
    "It is also important to provide explanations and interpretations that will be interesting for business based on your analysis.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
